{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPyH3D8xI9QucQZbQbQCdXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoaibkhan04086/Data-analysis/blob/main/gu_project_Next_word_prediction_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H-Le9PUgWRQl"
      },
      "outputs": [],
      "source": [
        "faqs=\"\"\"Galgotias University is a private university located in Greater Noida, Uttar Pradesh, India. It was established in 2011 by the Galgotias Educational Institutions. Here is some general information about the university:\n",
        "Location:\n",
        "Address: 1, Knowledge Park, Phase II, Greater Noida, Uttar Pradesh, India.\n",
        "Founding Year:\n",
        "Galgotias University was established in 2011.\n",
        "Ownership:\n",
        "It is a private university.\n",
        "Accreditations:\n",
        "The university is recognized by the University Grants Commission (UGC).\n",
        "Courses and Programs:\n",
        "Galgotias University offers a variety of undergraduate, postgraduate, and doctoral programs in fields such as engineering, management, law, pharmacy, humanities, and social sciences.\n",
        "Campus and Facilities:\n",
        "The university campus is equipped with modern facilities, including well-equipped classrooms, laboratories, hostels, sports facilities, and more.\n",
        "Affiliations:\n",
        "The university is affiliated with various professional bodies and organizations related to different disciplines.\n",
        "Rankings:\n",
        "University rankings may vary, and it's recommended to check the latest rankings from reliable sources.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "FdQbzN9vXgLt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()"
      ],
      "metadata": {
        "id": "WPnK5nGuXwx_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "eTQeeEdSX9cQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR8xSNmxYJrZ",
        "outputId": "99d4066a-2ea3-4e4e-dd78-bc0c3abe137f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KDQzPPfFgz9",
        "outputId": "e0d900a0-6a2f-4687-e458-2e0b7d672a65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'university': 1,\n",
              " 'the': 2,\n",
              " 'and': 3,\n",
              " 'is': 4,\n",
              " 'galgotias': 5,\n",
              " 'in': 6,\n",
              " 'a': 7,\n",
              " 'facilities': 8,\n",
              " 'rankings': 9,\n",
              " 'private': 10,\n",
              " 'greater': 11,\n",
              " 'noida': 12,\n",
              " 'uttar': 13,\n",
              " 'pradesh': 14,\n",
              " 'india': 15,\n",
              " 'it': 16,\n",
              " 'was': 17,\n",
              " 'established': 18,\n",
              " '2011': 19,\n",
              " 'by': 20,\n",
              " 'programs': 21,\n",
              " 'campus': 22,\n",
              " 'equipped': 23,\n",
              " 'with': 24,\n",
              " 'to': 25,\n",
              " 'located': 26,\n",
              " 'educational': 27,\n",
              " 'institutions': 28,\n",
              " 'here': 29,\n",
              " 'some': 30,\n",
              " 'general': 31,\n",
              " 'information': 32,\n",
              " 'about': 33,\n",
              " 'location': 34,\n",
              " 'address': 35,\n",
              " '1': 36,\n",
              " 'knowledge': 37,\n",
              " 'park': 38,\n",
              " 'phase': 39,\n",
              " 'ii': 40,\n",
              " 'founding': 41,\n",
              " 'year': 42,\n",
              " 'ownership': 43,\n",
              " 'accreditations': 44,\n",
              " 'recognized': 45,\n",
              " 'grants': 46,\n",
              " 'commission': 47,\n",
              " 'ugc': 48,\n",
              " 'courses': 49,\n",
              " 'offers': 50,\n",
              " 'variety': 51,\n",
              " 'of': 52,\n",
              " 'undergraduate': 53,\n",
              " 'postgraduate': 54,\n",
              " 'doctoral': 55,\n",
              " 'fields': 56,\n",
              " 'such': 57,\n",
              " 'as': 58,\n",
              " 'engineering': 59,\n",
              " 'management': 60,\n",
              " 'law': 61,\n",
              " 'pharmacy': 62,\n",
              " 'humanities': 63,\n",
              " 'social': 64,\n",
              " 'sciences': 65,\n",
              " 'modern': 66,\n",
              " 'including': 67,\n",
              " 'well': 68,\n",
              " 'classrooms': 69,\n",
              " 'laboratories': 70,\n",
              " 'hostels': 71,\n",
              " 'sports': 72,\n",
              " 'more': 73,\n",
              " 'affiliations': 74,\n",
              " 'affiliated': 75,\n",
              " 'various': 76,\n",
              " 'professional': 77,\n",
              " 'bodies': 78,\n",
              " 'organizations': 79,\n",
              " 'related': 80,\n",
              " 'different': 81,\n",
              " 'disciplines': 82,\n",
              " 'may': 83,\n",
              " 'vary': 84,\n",
              " \"it's\": 85,\n",
              " 'recommended': 86,\n",
              " 'check': 87,\n",
              " 'latest': 88,\n",
              " 'from': 89,\n",
              " 'reliable': 90,\n",
              " 'sources': 91}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence  in faqs.split('\\n'):\n",
        "  # print(sentence)\n",
        "  # print(token.texts_to_sequences([sentence])[0])\n",
        "  token_sentence=token.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1,len(token_sentence)):\n",
        "    input_sequences.append( token_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "m4hRK5u0Yudr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9_Eszs8ZL7F",
        "outputId": "65827386-a1b1-4416-b42f-499cd8c669df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1],\n",
              " [5, 1, 4],\n",
              " [5, 1, 4, 7],\n",
              " [5, 1, 4, 7, 10],\n",
              " [5, 1, 4, 7, 10, 1],\n",
              " [5, 1, 4, 7, 10, 1, 26],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19, 20],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19, 20, 2],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19, 20, 2, 5],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  2],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  2,\n",
              "  1],\n",
              " [35, 36],\n",
              " [35, 36, 37],\n",
              " [35, 36, 37, 38],\n",
              " [35, 36, 37, 38, 39],\n",
              " [35, 36, 37, 38, 39, 40],\n",
              " [35, 36, 37, 38, 39, 40, 11],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12, 13],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12, 13, 14],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12, 13, 14, 15],\n",
              " [41, 42],\n",
              " [5, 1],\n",
              " [5, 1, 17],\n",
              " [5, 1, 17, 18],\n",
              " [5, 1, 17, 18, 6],\n",
              " [5, 1, 17, 18, 6, 19],\n",
              " [16, 4],\n",
              " [16, 4, 7],\n",
              " [16, 4, 7, 10],\n",
              " [16, 4, 7, 10, 1],\n",
              " [2, 1],\n",
              " [2, 1, 4],\n",
              " [2, 1, 4, 45],\n",
              " [2, 1, 4, 45, 20],\n",
              " [2, 1, 4, 45, 20, 2],\n",
              " [2, 1, 4, 45, 20, 2, 1],\n",
              " [2, 1, 4, 45, 20, 2, 1, 46],\n",
              " [2, 1, 4, 45, 20, 2, 1, 46, 47],\n",
              " [2, 1, 4, 45, 20, 2, 1, 46, 47, 48],\n",
              " [49, 3],\n",
              " [49, 3, 21],\n",
              " [5, 1],\n",
              " [5, 1, 50],\n",
              " [5, 1, 50, 7],\n",
              " [5, 1, 50, 7, 51],\n",
              " [5, 1, 50, 7, 51, 52],\n",
              " [5, 1, 50, 7, 51, 52, 53],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60, 61],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60, 61, 62],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60, 61, 62, 63],\n",
              " [5,\n",
              "  1,\n",
              "  50,\n",
              "  7,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  3,\n",
              "  55,\n",
              "  21,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  3],\n",
              " [5,\n",
              "  1,\n",
              "  50,\n",
              "  7,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  3,\n",
              "  55,\n",
              "  21,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  3,\n",
              "  64],\n",
              " [5,\n",
              "  1,\n",
              "  50,\n",
              "  7,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  3,\n",
              "  55,\n",
              "  21,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  3,\n",
              "  64,\n",
              "  65],\n",
              " [22, 3],\n",
              " [22, 3, 8],\n",
              " [2, 1],\n",
              " [2, 1, 22],\n",
              " [2, 1, 22, 4],\n",
              " [2, 1, 22, 4, 23],\n",
              " [2, 1, 22, 4, 23, 24],\n",
              " [2, 1, 22, 4, 23, 24, 66],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72, 8],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72, 8, 3],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72, 8, 3, 73],\n",
              " [2, 1],\n",
              " [2, 1, 4],\n",
              " [2, 1, 4, 75],\n",
              " [2, 1, 4, 75, 24],\n",
              " [2, 1, 4, 75, 24, 76],\n",
              " [2, 1, 4, 75, 24, 76, 77],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80, 25],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80, 25, 81],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80, 25, 81, 82],\n",
              " [1, 9],\n",
              " [1, 9, 83],\n",
              " [1, 9, 83, 84],\n",
              " [1, 9, 83, 84, 3],\n",
              " [1, 9, 83, 84, 3, 85],\n",
              " [1, 9, 83, 84, 3, 85, 86],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9, 89],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9, 89, 90],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9, 89, 90, 91]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len =max([len(x) for x in input_sequences])\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltd-pnOFblTu",
        "outputId": "3999e3cc-71ed-4446-f066-c33d4fd86aef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "RhmDErpTcInK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(padded_input_sequences)"
      ],
      "metadata": {
        "id": "FNQx_13Aco-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "sE8t1-Jyc5DO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "Pw2DQekadL_B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWfaKc7ddRoK",
        "outputId": "f6bf5ffd-0bec-45a7-bedf-cd4a446a7386"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjSsMDC9dUBM",
        "outputId": "39f4e828-ba0b-46a4-8031-7abfeb12c7d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y = to_categorical(Y,num_classes=92)"
      ],
      "metadata": {
        "id": "aby5Uy6-da1j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEVu3xDCUd4c",
        "outputId": "e737c6b9-d568-48d8-86a8-be18246880ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "ABu0bfzIU1SW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(92,100,input_length=30))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(92, activation=\"softmax\"))\n"
      ],
      "metadata": {
        "id": "aOteiL99V5xC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3jtbLIZtXL-3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYrwWJdoXd94",
        "outputId": "b603d1e8-6068-46f0-df44-e233c99a006a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 30, 100)           9200      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 92)                13892     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173692 (678.48 KB)\n",
            "Trainable params: 173692 (678.48 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,Y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VhoQ471Xg6P",
        "outputId": "20da9556-b71b-439e-fffd-6bd0d881d544"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.0024 - accuracy: 0.8140\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.0137 - accuracy: 0.7829\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.0279 - accuracy: 0.7442\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.0220 - accuracy: 0.7829\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.9858 - accuracy: 0.8140\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.9624 - accuracy: 0.8140\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.9215 - accuracy: 0.8217\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.8887 - accuracy: 0.8217\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.8835 - accuracy: 0.7984\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.8460 - accuracy: 0.8527\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.8411 - accuracy: 0.8527\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.8380 - accuracy: 0.8605\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.8389 - accuracy: 0.8295\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.8282 - accuracy: 0.8450\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.8045 - accuracy: 0.8605\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.7849 - accuracy: 0.8527\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.7909 - accuracy: 0.8450\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.7841 - accuracy: 0.8372\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.7719 - accuracy: 0.8450\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.7913 - accuracy: 0.8450\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.7811 - accuracy: 0.8605\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.7624 - accuracy: 0.8450\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.8406 - accuracy: 0.7984\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.8235 - accuracy: 0.8295\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.7968 - accuracy: 0.8217\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.8794 - accuracy: 0.7907\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.8282 - accuracy: 0.8295\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.7985 - accuracy: 0.8605\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7574 - accuracy: 0.8682\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.6877 - accuracy: 0.8992\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6739 - accuracy: 0.8992\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6466 - accuracy: 0.9147\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.6319 - accuracy: 0.9225\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.6519 - accuracy: 0.8760\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.6500 - accuracy: 0.8837\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6420 - accuracy: 0.8837\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.6215 - accuracy: 0.8837\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.6049 - accuracy: 0.8915\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5901 - accuracy: 0.8992\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5886 - accuracy: 0.8837\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5727 - accuracy: 0.8915\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5506 - accuracy: 0.9147\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5419 - accuracy: 0.9070\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5400 - accuracy: 0.9070\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5393 - accuracy: 0.9070\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5392 - accuracy: 0.8992\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5284 - accuracy: 0.9147\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5271 - accuracy: 0.8992\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5204 - accuracy: 0.8992\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5045 - accuracy: 0.9070\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4866 - accuracy: 0.9302\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.4727 - accuracy: 0.9302\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.4767 - accuracy: 0.9380\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4921 - accuracy: 0.9147\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.4781 - accuracy: 0.9225\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.4543 - accuracy: 0.9225\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4422 - accuracy: 0.9302\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4264 - accuracy: 0.9535\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.4309 - accuracy: 0.9380\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.4399 - accuracy: 0.9302\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4411 - accuracy: 0.9225\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.4340 - accuracy: 0.9070\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.4264 - accuracy: 0.9147\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4297 - accuracy: 0.9302\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.4377 - accuracy: 0.9225\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.4273 - accuracy: 0.9070\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.4184 - accuracy: 0.9147\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.3986 - accuracy: 0.9147\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.3965 - accuracy: 0.9380\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.3979 - accuracy: 0.9302\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 0.3996 - accuracy: 0.9225\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.3988 - accuracy: 0.9225\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3847 - accuracy: 0.9302\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.3819 - accuracy: 0.9225\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.4014 - accuracy: 0.9225\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4099 - accuracy: 0.9225\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.3862 - accuracy: 0.9225\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.3602 - accuracy: 0.9380\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.3535 - accuracy: 0.9457\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.3414 - accuracy: 0.9457\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.3300 - accuracy: 0.9457\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3229 - accuracy: 0.9457\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.3169 - accuracy: 0.9535\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.3153 - accuracy: 0.9457\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.3049 - accuracy: 0.9457\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.3002 - accuracy: 0.9457\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2935 - accuracy: 0.9535\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.2945 - accuracy: 0.9612\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2999 - accuracy: 0.9457\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.2952 - accuracy: 0.9380\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.2895 - accuracy: 0.9380\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.2945 - accuracy: 0.9302\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2968 - accuracy: 0.9302\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2896 - accuracy: 0.9457\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.2845 - accuracy: 0.9457\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2804 - accuracy: 0.9535\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2823 - accuracy: 0.9535\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2725 - accuracy: 0.9535\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2717 - accuracy: 0.9612\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2583 - accuracy: 0.9690\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7968876be530>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "r_ZzBSQ0eg1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "hdEEhwONZMnD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "text = input(\"enter text : \")\n",
        "\n",
        "for i in range(5):\n",
        "  # tokenize\n",
        "  token_text = token.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=30, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in token.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" +word\n",
        "      print(text)\n",
        "      # time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ_Qel3BbVci",
        "outputId": "22b0961a-7ab0-4a15-de04-2d5c399f1023"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter text : the\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "the university\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "the university is\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "the university is affiliated\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "the university is affiliated with\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "the university is affiliated with various\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dujWlMirbk2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}